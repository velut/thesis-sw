---
title: "BOT Input Data Builder"
author: "Edoardo Scibona"
date: "February 19, 2018"
output: 
  html_document: 
    toc: yes
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This notebook contains an implementation of the algorithm that builds input data for automated approaches based on the keywords collected in the indirect task.
Specifically, the algorithm implemented here builds the input data for the BOT algorithm.

Steps 1 and 2 are the core steps of the input data builder that generate the required lists of keywords for each activity.

Steps 3 to 6 are specific to the input requirements of the BOT algorithm.

# Configuration

Required libraries
```{r message=FALSE}
library(tidyverse)
library(stringr)
library(SnowballC)
```

Input folder and files
```{r}
# Input folder's path.
# A folder named 'input' should be present in this notebook's root folder
INPUT_PATH <- file.path(getwd(), "input")

# Task output containing the keywords as written by workers (i.e., "raw keywords")
RAW_KW_FILE_PATH <- file.path(INPUT_PATH, "IT_01__raw__f1028243.csv")

# Task output containing the keywords written by workers
# but manually corrected by us (i.e., "clean keywords").
# For example, we fixed obvious spelling errors (e.g., "revoque" => "revoke")
CLEAN_KW_FILE_PATH <- file.path(INPUT_PATH, "IT_01__clean__f1028243.csv")

# Gold standard containing both the match and part-of activity pairs
GOLD_ALL_FILE_PATH <- file.path(INPUT_PATH, "gold_all.xml")

# Gold standard containing only the match activity pairs
GOLD_MATCH_FILE_PATH <- file.path(INPUT_PATH, "gold_match.xml")

# Gold standard containing only the part-of activity pairs
GOLD_POF_FILE_PATH <- file.path(INPUT_PATH, "gold_pof.xml")
```

# Step 1: Read and Prepare Input Data

In this step, we read data from the input folder.
Specifically, we read the indirect task output containing the lists of keywords.

Additionally, we prepare the raw data (both raw and clean keywords) for usage.

```{r}
# Prepare keyword tibbles for usage.
# By default spam keywords are kept in the output tibble.
prepare_kw <- function(tbl, remove_spam_keywords = FALSE) {
  tmp <- 
    tbl %>%
    # Keep only useful attributes
    select(
      unit_id = `_unit_id`,
      judgment_id = `_id`,
      worker_id = `_worker_id`,
      proc_id = process_id, 
      node_id, node_label,
      keywords = which_keywords_would_you_use_to_describe_the_highlighted_activity
    ) %>% 
    # Sort by process id and activity id
    arrange(proc_id, node_id)

  # Remove spam keywords if required
  if (remove_spam_keywords) {
    # Worker '40662071' entered 24 obvious spam judgments,
    # which we remove, and 1 valid judgment on node '2886',
    # which we keep.
    tmp_no_spam <-
      tmp %>% 
      filter(worker_id != "40662071" | node_id == "2886")
    
    tmp <- tmp_no_spam
  }

  # Remove 'worker_id' attribute (no longer necessary)
  tmp <- 
    tmp %>% 
    select(
      -worker_id
    ) %>% 
    mutate_if(
      is.numeric,
      as.character
    )
}
```

Get raw keywords (all or with spam removed)
```{r message=FALSE}
# Read file containing task output with raw keywords
read_raw_kw_file <- function() {
  read_csv(RAW_KW_FILE_PATH)
}

# Get a tibble containing all raw keywords
get_raw_kw_all <- function() {
  read_raw_kw_file() %>%
    prepare_kw()
}

# Get a tibble containing all raw keywords except spam ones
get_raw_kw_nospam <- function() {
  read_raw_kw_file() %>%
    prepare_kw(remove_spam_keywords = TRUE)
}

# Cache keywords to improve speed
CACHE_RAW_KW_ALL <- get_raw_kw_all()
CACHE_RAW_KW_NOSPAM <- get_raw_kw_nospam()

# Get a tibble containing all raw keywords (cached)
get_raw_kw_all_cached <- function() {
  CACHE_RAW_KW_ALL
}

# Get a tibble containing all raw keywords except spam ones (cached)
get_raw_kw_nospam_cached <- function() {
  CACHE_RAW_KW_NOSPAM
}
```

Get clean keywords (all or with spam removed)
```{r message=FALSE}
# Read file containing task output with clean keywords
read_clean_kw_file <- function() {
  read_delim(CLEAN_KW_FILE_PATH, ";", escape_double = FALSE, trim_ws = TRUE)
}

# Get a tibble containing all clean keywords
get_clean_kw_all <- function() {
  read_clean_kw_file() %>%
    prepare_kw()
}

# Get a tibble containing all clean keywords except spam ones
get_clean_kw_nospam <- function() {
  read_clean_kw_file() %>%
    prepare_kw(remove_spam_keywords = TRUE)
}

# Cache keywords to improve speed
CACHE_CLEAN_KW_ALL <- get_clean_kw_all()
CACHE_CLEAN_KW_NOSPAM <- get_clean_kw_nospam()

# Get a tibble containing all raw keywords (cached)
get_clean_kw_all_cached <- function() {
  CACHE_CLEAN_KW_ALL
}

# Get a tibble containing all raw keywords except spam ones (cached)
get_clean_kw_nospam_cached <- function() {
  CACHE_CLEAN_KW_NOSPAM
}
```

Get a tibble with the required kind of keywords
```{r}
# Return a tibble with the requested kind of keywords.
#
# @param use_clean_keywords TRUE if clean keywords should be used, FALSE if not
# @param remove_spam_keywords TRUE if spam judgments should be removed, FALSE if not
get_kw_data <- function(use_clean_keywords, remove_spam_keywords) {
  tmp <- NULL
  
  if (use_clean_keywords) {
    if (remove_spam_keywords) {
      tmp <- get_clean_kw_nospam_cached()
    } else {
      tmp <- get_clean_kw_all_cached()
    }
  } else {
    if (remove_spam_keywords) {
      tmp <- get_raw_kw_nospam_cached()
    } else {
      tmp <- get_raw_kw_all_cached()
    }
  }
  
  # Return tibble
  tmp
}
```

Get main attributes for all activities
```{r message=FALSE}
# Get a tibble with the 3 main attributes
# associated to each activity
get_all_activities <- function() {
  get_raw_kw_all() %>%
    distinct(
      proc_id, node_id, node_label
    )
}

CACHE_ALL_ACTIVITIES <- get_all_activities()
get_all_activities_cached <- function() {
  CACHE_ALL_ACTIVITIES
}
```

# Step 2: Build Keyword Lists

In this step, we build the keyword lists that will be used as the input data for automated approaches.

To build the keyword lists, we use two methods: union and intersection.

## Union Method

The union method consists in building larger and larger lists of keywords for each activity.
Specifically, for each activity we begin by considering the keywords suggested only by the first worker (out of 3 in our case), then we consider the keywords suggested by the first and second workers, finally we consider the keywords suggested by all three workers.

Thus, a bigger keyword list contains all the keywords found in the smaller lists.

```{r}
# Group keywords with the "union" method.
# In other words, for each activity first consider the keywords
# submitted only by one worker, then by two workers and so on.
# Each new keyword group contains the keywords of the previous group
# and adds a new list of keywords.
# @param kw_group_thr number indicating how many judgments should be considered
# (e.g., if 'kw_group_thr' is 2 then keywords submitted
# by the first two workers (out of three) will be returned).
# If 'kw_group_thr' is 0 then no keywords are returned.
get_kw_by_union <- function(use_clean_keywords, remove_spam_keywords, 
                            stem_keywords, kw_group_thr) {
  # Get the tbl containing the required keywords
  tmp <- get_kw_data(use_clean_keywords, remove_spam_keywords)
  
  # If the keyword group threshold is 0, then 
  # no keyword lists should be returned as the
  # final activity label will contain only the
  # words present in the original label.
  if (kw_group_thr == 0) {
    return(
      tmp %>% 
        distinct(
          proc_id, node_id
        ) %>% 
        mutate(
          kw_list = ""
        )
    )
  }

  # Separate keywords into one per row.
  # This is necessary for stemming
  tmp <- 
    tmp %>%  
    # Split the comma-separated lists of keywords
    # such that each row contains single keyword
    separate_rows(
      keywords,
      sep = ","
    ) %>% 
    rename(
      kw = keywords
    )
  
  # Stem keywords if needed
  if (stem_keywords) {
    tmp <- 
      tmp %>% 
      mutate(
        kw = wordStem(kw)
      )
  }
  
  # For each judgment, regroup the keywords
  # into a single space-separated string
  tmp <- 
    tmp %>% 
    group_by(
      unit_id, judgment_id,
      proc_id, node_id
    ) %>% 
    summarise(
      kw_list = str_c(kw, collapse = " ")
    ) %>% 
    ungroup()

  # Keep only the keyword in the required keyword group
  tmp <-
    tmp %>% 
    # For each unit:
    group_by(
      unit_id
    ) %>% 
    # keep the lists of keywords from the first 'kw_group_thr' judgments
    # (e.g., if 'kw_group_thr' == 2, then the keywords submitted by the first
    # and second workers that completed the unit are kept,
    # those submitted by the third worker are discarded).
    # This is the strategy at the core of the union method.
    filter(
      row_number() <= kw_group_thr
    ) %>%
    ungroup() %>%
    # Remove unneeded columns
    select(
      -c(unit_id, judgment_id)
    )
}
```

## Intersection Method

The intersection method consists in building smaller and smaller lists of keywords for each activity.
Specifically, for each activity we begin by considering the keywords suggested by at least one worker (i.e., all collected keywords), then we consider those suggested by at least two workers, finally we consider only the ones suggested by all three workers.

```{r}
# Group keywords with the "intersection" method.
# In other words, for each activity first consider the keywords
# suggested by at least one worker, then the keywords suggested
# by at least two workers and so on.
# Each new keyword group may lose some of the keywords of the previous group.
# Some activities may not have all the keyword groups.
# @param kw_group_thr number indicating how many overlapping judgments should be considered
# (e.g., if 'kw_group_thr' is 2, then the keywords submitted
# by at least two workers (out of three) will be returned).
get_kw_by_intersection <- function(use_clean_keywords, remove_spam_keywords,
                                   stem_keywords, kw_group_thr) {
  # Get the tbl containing the required keywords
  tmp <- get_kw_data(use_clean_keywords, remove_spam_keywords)

  # Separate keywords into one per row.
  # This is necessary for stemming and for
  # counting how many different workers
  # suggested a keyword.
  tmp <- 
    tmp %>%  
    # Split the comma-separated lists of keywords
    # such that each row contains single keyword
    separate_rows(
      keywords,
      sep = ","
    ) %>% 
    rename(
      kw = keywords
    )
  
  # Stem keywords if needed
  if (stem_keywords) {
    tmp <- 
      tmp %>% 
      mutate(
        kw = wordStem(kw)
      )
  }
  
  # For each keyword suggested in a unit
  # (i.e., for each keyword suggested for an activity)
  # count how many different workers suggested it.
  tmp <- 
    tmp %>% 
    group_by(
      unit_id, kw
    ) %>% 
    mutate(
      num_votes = n_distinct(judgment_id)
    ) %>% 
    ungroup()

  # Keep keywords in the required vote group 
  # (e.g., at least 1 vote out of 3, 2/3, 3/3)
  tmp <- 
    tmp %>% 
    # Keep keywords with at least 'kw_group_thr' votes.
    # This is the strategy at the core of the "intersection" method.
    filter(
      num_votes >= kw_group_thr
    ) %>%
    # Remove unneeded columns
    select(
      -c(unit_id, judgment_id, num_votes)
    )
  
  # Collapse the keywords for each activity
  # (i.e., from one row per keyword
  # change to one row per string of keywords).
  tmp <-
    tmp %>%
    group_by(
      proc_id, node_id
    ) %>%
    # For each activity keep only distinct keywords,
    # otherwise the final keyword list would look like
    # "letter letter letter send .." if for example
    # all three workers suggested "letter" as a keyword
    distinct(
      kw
    ) %>%
    summarise(
      kw_list = str_c(kw, collapse = " ")
    ) %>% 
    ungroup()
  
  # Not all activities may have keywords selected
  # by at least 'kw_group_thr' workers.
  # Since we still want a tbl with the full list of activities, 
  # we join the tibble containing all the existing activities
  # with our 'tmp' tibble, which may be missing some activities.
  # Then we replace NA values in the keyword list attribute
  # (caused by missing activities in 'tmp') with empty strings.
  tmp <- 
    get_all_activities_cached() %>% 
    left_join(
      tmp,
      by = c("proc_id", "node_id")
    ) %>% 
    # Replace NA with empty string for activities without a keyword list
    mutate(
      kw_list = str_replace_na(kw_list, replacement = "")
    ) %>% 
    # Remove unneeded attribute
    select(
      -node_label
    )
}
```

# Step 3: Build XML Elements

In this step, we build the XML elements that compose the input required by the BOT algorithm.
This step and the XML elements are specific to the BOT algorithm.

```{r}
# Helper function for indentation
fmt_indent <- function(times) {
  indent <- '    '
  str_dup(indent, times)
}
```

XML Node element builder
```{r}
# Build the string that represents a single node (activity) in xml
to_xml_node <- function(node_id, node_label, kw_vec) {
  # Indentations
  i2 <- fmt_indent(2)
  i3 <- fmt_indent(3)
  i4 <- fmt_indent(4)
  
  # Node tag with custom node (activity) id
  node_open_tag <- str_c(
    i2,
    '<Node height="40.0" id="',
    node_id,
    '" type="petri net transition" width="40.0" x="100.0" y="100.0">'
  )
  node_close_tag <- str_c(i2, '</Node>')
  
  # Label tag with input label
  label_open_tag <- str_c(i3, '<Label>')
  label_close_tag <- str_c(i3, '</Label>')
  
  # Escape '<' and '>' characters
  escaped_node_label <- str_replace_all(
    node_label,
    c("<" = "&lt;", ">" = "&gt;")
  )
  label_text <- str_c(i4, escaped_node_label)
  
  # Text containing the keywords
  # associated to the activity
  keywords_text <- NULL

  # If there are some keywords for this activity,
  # indent them to be aligned string representing
  # the activity's label.
  # Note: 'kw_vec' should be a vector of strings
  # (e.g., 'c("key1 key2", "key3 key4")')
  if (!is_empty(kw_vec)) {
    keywords_text <- 
      # Transform into a single column tbl
      # for easier manipulation
      tibble(
        kw = kw_vec
      ) %>% 
      # Indent keywords
      mutate(
        kw = str_c(i4, kw)
      ) %>% 
      # Keep only rows which contain keywords
      # (i.e., are not only empty space)
      filter(
        str_trim(kw) != ""
      ) %>% 
      # Transform to vector again
      .$kw  
  }
  
  # Vector containing all the string elements
  # needed to build an xml node representing
  # a single activity
  node_elem <- c(
    i2,
    node_open_tag,
    label_open_tag,
    label_text,
    keywords_text,
    label_close_tag,
    node_close_tag,
    i2
  )
  # Concat all the above strings separated by newlines
  str_c(node_elem, collapse = "\n")
}
```

XML Process element builder
```{r}
# Build the string that represents a process in xml
to_xml_process <- function(proc_id, proc_name, xml_nodes) {
  i1 <- fmt_indent(1)

  # Process open tag
  # with custom process id and
  # process name attributes
  process_open_tag <- str_c(
    i1,
    '<Process id="',
    proc_id,
    '" name="',
    proc_name,
    '" type="Petri Netz">'
  )

  process_close_tag <- str_c(
    i1,
    '</Process>'
  )

  # Vector of strings composing the process xml element
  process_elem <- c(
    i1,
    process_open_tag,
    xml_nodes,
    process_close_tag,
    i1
  )
  str_c(process_elem, collapse = "\n")
}
```

XML Models content builder
```{r}
# Build the string that represents a collection of processes in xml.
# This string should be written to the 'models.xml' file used by BOT
to_xml_model <- function(xml_processes) {
  xml_tag <- '<?xml version="1.0" encoding="UTF-8"?>'
  processes_open_tag <- '<Processes>'
  processes_close_tag <- '</Processes>'
  
  models <- c(
    xml_tag,
    processes_open_tag,
    xml_processes,
    processes_close_tag
  )
  str_c(models, collapse = "\n")
}
```

# Step 4: Build XML Model File Contents

```{r}
# Parse XML model configurations
# (e.g., "UA_Union_Gold_File_0_Key_NoSpam_NoStem")
parse_config <- function(config) {
  tmp <- 
    # Put config string into tbl
    tibble(cfg = config) %>% 
    # Parse config
    separate(
      cfg,
      into = c(
        # Dataset (i.e., "UA")
        "dataset",
        # "Union" or "Intersection"
        "kw_method",
        # "GoldAll", "GoldMatch", "GoldPartOf"
        "gold",
        # "Base", "Raw", "Clean"
        "use_clean_keywords",
        # "0", "1", "2", "3"
        "kw_group_thr",
        # "Keywords", string to be removed
        "rm_kw_string",
        # "Default", "NoSpam"
        "remove_spam_keywords",
        # "Stemmed", "NoStem"
        "stem_keywords"
      )
    ) %>% 
    mutate(
      kw_method = str_to_lower(kw_method),
      use_clean_keywords = str_detect(use_clean_keywords, "Clean"),
      kw_group_thr = as.numeric(kw_group_thr),
      remove_spam_keywords = str_detect(remove_spam_keywords, "NoSpam"),
      stem_keywords = str_detect(stem_keywords, "Stemmed")
    ) %>%
    select(
      -rm_kw_string
    )
}
```

```{r}
# Build an xml model used as input given a specific configuration
build_xml_model_with_config <- function(config) {
  # Parse config string
  cfg <- parse_config(config)
  
  # Get the keywords tbl based on required method
  # and keyword options
  kw_tbl <- NULL
  
  if (cfg$kw_method == "union") {
    kw_tbl <- get_kw_by_union(
        use_clean_keywords = cfg$use_clean_keywords, 
        remove_spam_keywords = cfg$remove_spam_keywords,
        stem_keywords = cfg$stem_keywords,
        kw_group_thr = cfg$kw_group_thr
    )
  }
  
  if (cfg$kw_method == "intersection") {
    kw_tbl <- get_kw_by_intersection(
        use_clean_keywords = cfg$use_clean_keywords, 
        remove_spam_keywords = cfg$remove_spam_keywords,
        stem_keywords = cfg$stem_keywords,
        kw_group_thr = cfg$kw_group_thr
    )
  }
  
  # Build the model file contents
  
  # Join activity data with keywords
  tmp <- 
    get_all_activities_cached() %>% 
    left_join(
      kw_tbl,
      by = c("proc_id", "node_id")
    )
  
  # For each activity in a process,
  # build the corresponding xml node element
  tmp <- 
    tmp %>% 
    group_by(
      proc_id, node_id
    ) %>% 
    summarise(
      xml_node = to_xml_node(
        # ATTENTION: keep only a single string and
        # not a vector for 'node_id' and 'node_label'
        node_id[1],
        node_label[1],
        # Vector with strings representing lists of keywords
        kw_list
      )
    ) %>% 
    ungroup()
  
  # Add 'proc_name' attribute
  tmp <- 
    tmp %>% 
    mutate(
      # Initialize with 'proc_id' string
      proc_name = proc_id,
      # Add proper names by replacement
      proc_name = str_replace(proc_name, "82", "Cologne"),
      proc_name = str_replace(proc_name, "83", "Frankfurt"),
      proc_name = str_replace(proc_name, "84", "FU Berlin"),
      proc_name = str_replace(proc_name, "89", "TU Munich")
    )
  
  # For each process build the xml process element
  # containing the previously built xml node elements
  tmp <- 
    tmp %>% 
    group_by(
      proc_id
    ) %>% 
    summarise(
      xml_process = to_xml_process(
        # Keep only a single string as before
        proc_id[1],
        proc_name[1],
        # Vector containing xml node elements
        xml_node
      )
    ) %>% 
    ungroup()
  
  # Finally bundle the previously built xml process elements
  # in a single xml model element to be written to the 'models.xml' file
  tmp <- 
    tmp %>% 
    summarise(
      xml_model = to_xml_model(
        xml_process
      )
    )
  
  # Return the string representing the built xml model
  tmp$xml_model
}
```

# Step 5: Generate BOT Input Data Configurations

```{r}
# Return the vector containing all the configs to be built.
#
# Input data configurations naming convention:
#
#  UA: University Admission dataset
#
#  Union: 
#    Use the "union" method for keywords.
#    This method considers keyword lists that always increase in size
#    and contain the previous list of keywords (e.g., keywords from the first
#    judgment, keywords from the first and second judgment, and so on).
#
#  Intersection: 
#    Use the "intersection" method for keywords.
#    This method considers keyword lists that always decrease in size
#    and contain keywords suggested by at least N workers out of all workers
#    (e.g., keywords suggested by at least one worker, by at least two workers, and so on).
#
#  GoldAll: Gold standard includes both match and part-of relationships
#  GoldMatch: Gold standard includes only match relationships
#  GoldPartOf: Gold standard includes only part-of relationships
#
#  Base: 
#    Same as the Raw file, different name for later parsing of outputs.
#    Used only for base configs with 0 keywords (only labels)
#  Raw: Use file with unedited keywords
#  Clean: Use file with fixed keywords (e.g., "revoque" changed to "revoke")
#
#  0_Keywords: models file includes only the activities labels
#  1_Keywords: models file includes the activities labels and the first group of keywords
#  2_Keywords: models file includes the activities labels and the second group of keywords
#  3_Keywords: models file includes the activities labels and the third group of keywords
#  For the above configs the contents of keyword groups depend on the selected method (i.e Union/Intersection)
#
#  NoSpam: 
#    Spam keywords are removed from the dataset.
#    When using this option some activities will have fewer sets of keywords per activity
#    than the chosen configuration (e.g., with '3_Keywords' some activities
#    will have two sets of keywords as one set is spam)
#  Default: Keep all the available keywords
#
#  NoStem: Don't stem keywords
#  Stemmed: Stem keywords
get_input_data_configs <- function() {
  # Vectors with config parameters
  dataset <- "UA"
  kw_method <- c(
    "Union",
    "Intersection"
  )
  gold <- c(
    "GoldAll",
    "GoldMatch",
    "GoldPartOf"
  )
  file_type <- c(
    "Base",
    "Raw",
    "Clean"
  )
  kw_group_thr <- c(
    "0", "1", "2", "3"
  )
  kw_group_str <- "Keywords"
  spam_cfg <- c(
    "Default",
    "NoSpam"
  )
  stem_cfg <- c(
    "Stemmed",
    "NoStem"
  )
  
  # Generate all possible combinations
  # of config attributes
  tmp <- 
    expand.grid(
      dataset = dataset,
      kw_method = kw_method,
      gold = gold,
      file_type = file_type,
      kw_group_thr = kw_group_thr,
      kw_group_str = kw_group_str,
      spam_cfg = spam_cfg,
      stem_cfg = stem_cfg
    )
  
  # Remove unneeded configs
  # and sort tbl
  tmp <- 
    tmp %>% 
    filter(
      # Configurations containing only original labels do not need
      # a threshold different from "0".
      !(file_type == "Base" & kw_group_thr != "0"),
      # Configurations containing any number of keywords do not need
      # a "0" threshold.
      !(file_type != "Base" & kw_group_thr == "0"),
      # Intersection configs do not need an at least "0" threshold
      # as it's the same as the at least "1" threshold.
      !(kw_method == "Intersection" & kw_group_thr == "0")
    ) %>% 
    arrange(
      dataset, kw_method, gold,
      file_type, kw_group_thr,
      spam_cfg, stem_cfg
    )
  
  # Unite all the columns in a single string
  # representing the config
  tmp <- 
    tmp %>% 
    unite(
      dataset:stem_cfg,
      col = "config",
      sep = "_"
    )
  
  last_row_idx <- nrow(tmp)
  
  # Build a column with configs quoted and separated
  # by a comma.
  # This list of configs is then written to file and can be
  # used in BOT source as a list.
  tmp <- 
    tmp %>%
    mutate(
      config_quote_and_comma = str_c(
        # Surround config with quotes
        "\"", config, "\"",
        # Add comma only to the first n-1 rows
        if_else(
          row_number() != last_row_idx,
          ",",
          ""
        )
      )
    )
  
  write_file(
    str_c(tmp$config_quote_and_comma, collapse = "\n"),
    "BUILT_CONFIGS_LIST_QUOTED.txt"
  )
  
  write_file(
    str_c(tmp$config, collapse = "\n"),
    "BUILT_CONFIGS_LIST_BARE.txt"
  )
  
  # Return vector with configs
  tmp$config
}
```

# Step 6: Write BOT Input Data Configurations

```{r}
write_bot_input_data_config <- function(config) {
  # Create folders
  dir.create(config)
  modelPath <- file.path(config, "model")
  dir.create(modelPath)
  
  # ATTENTION: 
  # BOT default gold folder name is "gold standard" and not "gold".
  # Remember to change the folder name here or in BOT's source
  # if needed.
  goldPath <- file.path(config, "gold")
  dir.create(goldPath)
  
  use_gold_all <- str_detect(config, "GoldAll")
  use_gold_match <- str_detect(config, "GoldMatch")
  use_gold_part_of <- str_detect(config, "GoldPartOf")
  
  gold_file <- NULL
  
  if (use_gold_all) {
    gold_file <- GOLD_ALL_FILE_PATH
  }
  
  if (use_gold_match) {
    gold_file <- GOLD_MATCH_FILE_PATH
  }
  
  if (use_gold_part_of) {
    gold_file <- GOLD_POF_FILE_PATH
  }
  
  # Copy gold standard to gold folder and name it 'correspondences.xml',
  # as required by BOT
  file.copy(gold_file, file.path(goldPath, "correspondences.xml"))
  
  # Build 'models.xml' file contents
  models_xml <- build_xml_model_with_config(config)
  
  # Write 'models.xml' (name required by BOT) file to model folder
  fc <- file(file.path(modelPath, "models.xml"))
  write_file(models_xml, fc)
}
```

```{r}
# Write the all the required input data configurations
# for the BOT algorithm
write_all_bot_input_data_configs <- function() {
  orig_dir <- getwd()
  output_dir <- "BOT_INPUT_DATA"
  
  if (dir.exists(output_dir)) {
    warning(
      "Output directory already exists.",
      "Rename it or move it in order to build the new input data.",
      "Stopping."
    )
    return()
  }
  
  # Create output dir and switch to it
  dir.create(output_dir)
  setwd(output_dir)
  
  # Get and build all input data configurations
  configs <- get_input_data_configs()
  sapply(configs, write_bot_input_data_config)
  
  # Restore previous working dir
  setwd(orig_dir)
  
  print(
    str_c("BOT input data written to folder:\n", file.path(orig_dir, output_dir))
  )
}
```

# Main

```{r message=FALSE}
# To write all the BOT input data configurations,
# load this file into RStudio, uncomment the last line
# in this cell, and run all cells.
# The process may take a while.
#
# Note: If any BOT input data configurations
# already exist, the program will stop
# to prevent overwriting them.

# Uncomment the following line to write the BOT input data configs
# write_all_bot_input_data_configs()
```
